---
message: |-
  لو سمحتم يا شباب فكرة إني أعمل logs او monitoring لكل العمليات اللي تمت من المستخدمين على سستم  سواء كانت update او delete أو Insert إيه أفضل طريقة لتنفيذها؟
  هل منطقي كل جدول في الداتابيز يكون قصاده جدول logs ولو ده منطقي هل تبقي نفس Scheme?
  وهل لو ده صحيح هل الأفضل تتم عملية النسخ دي في الكود ولا الأفضل الإعتمادية على Database Triggers?
  ولا فيه حلول متاحة أفضل من الفكرة دي؟
from:
  name: Mohamed Mohamed
  id: '1352596088179873'
type: status
created_time: '2017-06-13T21:13:18+0000'
updated_time: '2017-06-15T07:04:22+0000'
permalink_url: https://www.facebook.com/groups/egyptian.geeks/permalink/1514662178573485/
shares:
  count: 1
id: '172338516139198_1514662178573485'
reactions:
  data:
  - id: '1494202580648907'
    name: Abd Alrhman Serag
    type: LIKE
  - id: '2012132359064709'
    name: Mohamed Ragab
    type: LIKE
  - id: '10156223879047941'
    name: Tamer Elfeky
    type: LIKE
  - id: '1999765416908747'
    name: Ahmed Khalifa
    type: LIKE
  paging:
    cursors:
      before: TVRBd01EQXhOemMxTXpjeU1UWXpPakUwT1RjME5EZA3dPRGc2TWpVME1EazJNVFl4TXc9PQZDZD
      after: TVRBd01EQTJNalU1TWpNNE9EVXlPakUwT1Rjek9EZAzFOelU2TWpVME1EazJNVFl4TXc9PQZDZD
comments:
  data:
  - created_time: '2017-06-13T21:46:09+0000'
    from:
      name: Mohamed Shaaban
      id: '10156259295924301'
    message: ايه الهدف من ال logs وال monitoring؟
    id: '1514690675237302'
  - created_time: '2017-06-13T21:55:28+0000'
    from:
      name: Ibrahim Hussein
      id: '10155686945529760'
    message: "It can be done using one table/model to store all activities/logs, each
      record will hold the object id (the one on which the event is happening), object
      type (the object type you are logging. ex: article, account, product...), action
      type (create, update...), changes (can be stored in json for example). This
      way you will use one schema to manage different object types. For the second
      question, I think it will depend on the details. But in general I think it's
      better to keep the logging in your application layer for more data consistency.
      \nAlso based on what language or framework you do use, you'll probably find
      available tools to do the job for you. We work with Rails and we use https://github.com/collectiveidea/audited"
    id: '1514695945236775'
  - created_time: '2017-06-13T22:03:38+0000'
    from:
      name: Aly Saleh
      id: '10157135743444899'
    message: |-
      There are solutions especially designed for monitoring and analytics. You said you want to log insert, update and delete, but you did not say how you intend to query them or use them.  I would not recommend using a relational database.
      Anyways, you can check the ELK stack from elastic, https://www.elastic.co/products  or grafana with influx http://docs.grafana.org/features/datasources/influxdb/.
    id: '1514701481902888'
  - created_time: '2017-06-13T22:58:36+0000'
    from:
      name: Ibrahim Zaki
      id: '10157017423792738'
    message: "انت بتتكلم فى ثلاث مواضيع \n1- logging \n2 - audit \n3- monitoring \nناخد
      الأول \nالمفروض إن اى تطبيق مهما كان حجمه ي لوج كل أكشن بيتم فى التطبيق على
      كل مستوياته بكل مستويات اللوجنج المتاحة \nيعنى مثلا فى بدايه كل فنكشن و نهايتها
      تقول معلومات انا ب بدأ فى و ظيفة كذا و بنهى كذا بمستوى لوجنج مثلا إنفو \nو لو
      فيه اكسبشن بترميه في اللوج فى مستوى error \nوهكذا \nليه بقى علشان أولا تعرف
      تعمل ديبجينج لأى  مشكلة و مثلا كمان لدراسة سلوك النظام و مستخدميه و من ثمة تطويره
      \nو دا فى كل استاك هتلاقى مكتبات تنفذه على مستوى السستم بشكل مركزى علشان تتحكم
      فى أنهى مستوى انت بكتب لوج \nو ممكن كمان تستفيد من أفكار aspects في تنفيذ الكلام
      دا بسهولة \nأما الحاجة التانية في هى audit \nهيا بقى نفس الحاجة الأولى بس بغرض
      ال administration \nو فيها بتخزين فى أى مخذن  مين غير إيه امته و ممكن كمان ليه
      و أو حتى غير من أيه لأيه و الموديل بتاعها بيختلف شوية من شغل لشغل\nو برده هتلاقى
      مكتبات حسب الاستاك بتاعك \nاما المونيتورنج دا حكاية تانيه هدفها متابعة Performance
      بتاعة التطبيق ليف و تسجيل و ارسال تقارير عن أى أخطاء أو انحرافات يتم تحديد معايرها
      سلفا \nو إظهار حالة كل مكونات التطبيق انيا \nو برده فيه مكتبات كتير لي كدا \nبس
      الثلاث مواضيع مترابطين جدا و شيقين"
    id: '1514730971899939'
  - created_time: '2017-06-14T01:57:54+0000'
    from:
      name: Mohamed Ali
      id: '10155700064031636'
    message: |-
      لو الغرض استعادة البيانات لو حاجة حذفت بالغلط فانت بتتكلم عن ال transaction log، وده خاصية موجودة في الداتابيز وبيتحكم فيها الادمن، لو حبيت تعمل جداول اضافية عشان تسترجع الداتا بشكل يدوي فده هيعمل مشاكل في ال consistency بتاعة الداتا، ال foreign keys هتتلخبط مثلا
      وممكن تعمل audit log تسجل فيه مين عمل ايه وامتى، وتسجل فيه المحاولات المرفوضة كمان، حد حاول يمسح حاجة مش مصرح له بيها وهكذا
    id: '1514882121884824'
  - created_time: '2017-06-14T02:19:57+0000'
    from:
      name: Ahmad Hisham
      id: '10159889607765058'
    message: |-
      بص ... هو منذ بدء الخليقة الرقمية ومواضيع ال Logging & Moniroting ده من المواضيع إللي الناس إهتمت بيها ... فهو بشكل عام فيه حلول كتيرة جدا وفيه حاجة لكل حجم ... يعني لو البرنامج بتاعك distributed فعملية تجميع ال Logs لنقطة مركزية بتبقي مهمة مثلا ... أو لو إنت شغال علي نظام زي Amazon ففيه عندهم خدمات مختلفة زي CloudWatch لل Monitoring و Kinesis لمعالجة ال Logs في ال Realtime أو EMR or Redshift لمعالجة ال Logs in Batch
      ممكن تبص علي اللينك
      https://aws.amazon.com/getting-started/projects/build-log-analytics-solution/
    id: '1514899231883113'
  - created_time: '2017-06-14T02:31:37+0000'
    from:
      name: Ahmad Hisham
      id: '10159889607765058'
    message: لو إنت بتعمل النظام بتاعك On premise فكك من موضوع ال AWS (بس إقرأ المقالة
      ... فيها Concepts حلوة)... وحسب اللغة وال Server بتاعك هاتلاقي حلول مختلفة ...
      بس هو بشكل عام إبعد عن ال Logging in Database، قواعد البيانات (خصوصا ال SQL)
      مش متصممة لعملية ال streaming for low criticality high volume data من غير ما
      يتعملها Tweaking & adjustments كتير ... ال Logs في Text files وبعد كده إعملها
      Processing/Summarization وخزن النتايج بالوقت والتاريخ في الDatabase - preferably
      NoSQL علشان تعرف تبص عليها بعدين وتعمل Trend Analysis مثلا
    id: '1514909115215458'
  - created_time: '2017-06-14T02:45:00+0000'
    from:
      name: Ahmad Hisham
      id: '10159889607765058'
    message: |-
      كمثال: أنا في واحد من النظم إللي إشتغلت فيها كنا بنشتغل بطريقة:
      1. Configure the Application Server (NGINX/Apache/IIS) to produce 1 line logs containing all the details needed (Date/Time, request URL, requester IP, User agent details, result success/failure, return HTTP code, ...)
      It is important not to log in multiline to streamline the log processing situation afterwards
      2. Make a script to ship logs periodically (every xx minutes a cron job/scheduled task is invoked to move the current logs to new location and rename them to append date/time)
      Based on your server, you may need to issue a command for it to stop writing in the current log first, or configure it to start writing new log file every xx minutes)
      3. If you are doing a distributed system/load balanced/clustered/micro services architecture, you can make your script ship the logs into a central network location so that you can see the full picture of you system in one log analysis pipeline (you need to include the server node name in the log file name/path to distinguish between the different servers)
      4. Make a separate process/machine to read the logs and put them into a log analysis data store (we used Logstash for Logs reading and transformation, and Elasticsearch for Logs events storage and analysis)
      5. After a log read is complete, you can delete the log file or compress it and archive it for sometime, but delete any log file dating more than xx days  (you can even archive it in Amazon Glacier, but that is usually an overkill)
      6. Use a frontend Analytics tool to visualize the data stored in the logs data store (we used Kibana as an online tool to visualize the logs analysis data inside Elasticsearch)

      For more information on Elasticsearch/Logstash/Kibana, you can see
      https://www.elastic.co/products
    id: '1514923968547306'
  - created_time: '2017-06-14T09:10:21+0000'
    from:
      name: Nabiel Kmal
      id: '913852418772611'
    message: مالوش لازمة تعمل manual auditing لان الـ database engine بيعمل كده وبيسجل
      كل الـ crud operation في ldf file ده لو انت بتستعمل ms sql server لكن لو عاوز
      تعمل logging ممكن تستعمل log4net , خفيفة و thread friendly و تقدر تعمل تحكم
      كامل في نوع ال logging لكل مستخدم و module من خلال ال configuration file
    id: '1515192828520420'
  - created_time: '2017-06-14T10:02:11+0000'
    from:
      name: Mahmoud M. Ibrahim
      id: '10156091659585979'
    message: "In my opinion,  you can use CDC (chanfe data capture)  solution and
      host logged data at another DB,  simply you won't suffer from performance degradation
      as CDC tool capture changes (insert,  update or delete)  from db logs not from
      DB it self, and every transaction will be logged to the another DB will be flagged
      with insert or update or delete flags (I,U,D), \n\nThere are many good known
      tools in  the market like (Informatica powerexchange,  oracle golden gate and
      also IBM) \n\nMost if them support different types of DBMS like (SQL Server,
      Oracle,.... etc)\n\nHope that helped you, for more info you can contact me as
      i worked with them and have good experience with it."
    id: '1515227201850316'
  - created_time: '2017-06-15T07:04:19+0000'
    from:
      name: Osama Nour
      id: '1665988986754750'
    message: |-
      Ahmed Ragae El-Gebaly
      Yasin Hazem H
    id: '1516191208420582'
  paging:
    cursors:
      before: WTI5dGJXVnVkRjlqZAFhKemIzSTZANVFV4TkRZANU1EWTNOVEl6TnpNd01qb3hORGszTXprd016WTUZD
      after: WTI5dGJXVnVkRjlqZAFhKemIzSTZANVFV4TmpFNU1USXdPRFF5TURVNE1qb3hORGszTlRFd01qWXcZD
