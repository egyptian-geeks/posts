---
message: i have web app that make request to data base each 5 seconds to get the last
  updated data from DB i am using AJAX request with interval each 5 seconds  ,  if
  there is  another way to make this   ?
from:
  name: Mahmoud Mahdy
  id: '2117141178517242'
type: status
created_time: '2013-12-25T05:36:58+0000'
updated_time: '2013-12-26T08:29:43+0000'
permalink_url: https://www.facebook.com/groups/egyptian.geeks/permalink/674932422546469/
id: '172338516139198_674932422546469'
comments:
  data:
  - created_time: '2013-12-25T14:36:41+0000'
    from:
      name: Khaled M. Diab
      id: '10215626626127168'
    message: "Thanks Amr Eldib .. I have one comment on SignalR\nSignalR uses websockets
      (for low-latency bi-directional communication between server and client, which
      is good) .. \nWebsockets are connection-oriented; this means one point of failure
      and less scalability for the server-side. I don't know how SignalR (or similar
      libs) handles failure. But one solution is to use in-memory store from the server
      side like Redis. It's fast, because it's in-memory. It's reliable because it
      has dump. You can replicate it to have read scalability. You can partition its
      data to get write scalability. \nThat's why for high scalability, I may prefer
      http-based communication. what do you think?"
    id: '675096652530046'
  - created_time: '2013-12-25T18:01:41+0000'
    from:
      name: Mohamed Alaa El Din
      id: '1573619512716214'
    message: I'm not sure if Socket.io is supported in .NET or not
    id: '675172305855814'
  - created_time: '2013-12-25T18:22:45+0000'
    from:
      name: Hady Mahmoud
      id: '10213443570697789'
    message: "Designing for failure is an architectural decision not the responsibility
      of an infrastructural technology and isn't certainly provided out of the box
      for most cases.\nBy your definition that WebSockets are connection-oriented
      (stateful) thus they are prune to SPOFs should also be extended to HTTP. HTTP
      is an application layer protocol, it's underlaying implementation is built on
      TCP which is a stateful transport layer protocol.\n\nThat doesn't mean HTTP
      can't be implemented on any other transport protocol, most application layer
      protocols assume reliability, ensured delivery, error tracking and recovery
      which TCP as a transport layer protocol promises.\n\nThat being said, by your
      definition; the problem still persists. Whether your communication layer is
      designed to be stateful or stateless, doing http requests alone wouldn't mitigate
      the risk of a server melt down. In fact, it's likely to amplify it.\n\nWhy?
      Because of the very nature of http being stateless, regardless of the transport
      protocol it's running on. Stateless means you can't keep a bi-directional connection
      opened long enough for the entire session. Which poses a problem, the handshake
      is expensive. It certainly depends on your architecture, server of choice and
      network configurations, but it's safe to assume the initiation of the connection,
      the request handling, request processing, connection teardown and all the roundtrips
      in between will likely melt your server.\n\nDifferent http servers handle connections
      differently, as such will have different memory footprints. Your eventual goal
      is to keep your backlog empty, your ram free and your cpu responsive.\n\nI can't
      see how Redis fits in the current problem domain, you'll eventually need to
      transport data back and forth between a browser and a server. Redis wont help
      you with that. Redis can come handy when your architecture starts branching
      multiple server daemons, multiple services and multiple boxes, then redis can
      be used as a reliable message bus or a backend for a message bus. In either
      way, it's out of the scope of the problem at hand here.\n\nIt's your responsibility
      to design for scalability, both on client and server sides. Using a WebSocket
      server, or doing it old school with plain http requests (long-polling is one
      alternative), if your server goes down the client will still get affected. It's
      your job to detect a connection failure, reinitiate the connection, notify the
      user...etc.\n\nOn the server side, you'll definitely need to branch out, dedicated
      boxes for each service (http, application, database, cache) you'll need to balance
      your load, so you'll likely design a routing mesh upfront and implement reverse
      proxies. One node fails, another is reachable, it's seamless for the client
      since you're already handling such cases. You'll likely keep some data cached
      in memory for such service disruptions, or dumped to a file (redis clusters
      can be configured for such stuff)...etc. \n\nYou'll need to re-architect your
      approach to data storage, data duplication and data loss. So you'll be dealing
      with a lot of database sharding. If you got persistent sessions, you'll need
      to worry about sticky sessions.\n\nI mean, list goes on really... Scalability
      is an architecture not a feature, concurrency is a design which can either be
      given for free (erlang/otp, scala/akka) or left for you to handle.\n\nIt has
      nothing to do with WebSockets vs. Comet (Ajax based long-polling, Hidden iframes...etc.)\n\nHope
      this super lengthly comment helps."
    id: '675178625855182'
  - created_time: '2013-12-25T19:30:48+0000'
    from:
      name: Khaled M. Diab
      id: '10215626626127168'
    message: |-
      Thanks for the comment .. Yes, I understand what you wrote; the protocol part, the low-latency etc... BTW, I think you're right that scalability is an architecture choice.
      For Http, we forget about KeepAlive (http1.1). If it's used, then we can get rid of most of connection initiation overhead

      For redis part, I think it can be used to store client/server connection information. and then the server handles transport when "wakes up" from failure ..

      For the "It has nothing to do with WebSockets vs. Comet". This depends on the server implementation, if scalable or not.

      Also, you may have a look at HTTP2.0 and SPDY, they use the same http semantics but with better performance. Also, htt2.0 introduces the server push.
    id: '675206389185739'
  - created_time: '2013-12-26T05:41:09+0000'
    from:
      name: Mahmoud Mahdy
      id: '2117141178517242'
    message: "i find this  websotckt supported for .net  \nhttp://xsockets.net/"
    id: '675421462497565'
  - created_time: '2013-12-26T08:29:43+0000'
    from:
      name: Moђameđ Ebieđ
      id: '10211108691457136'
    message: yes i would recommend SignalR
    id: '675483669158011'
  paging:
    cursors:
      before: WTI5dGJXVnVkRjlqZAFhKemIzSTZAOamMxTURrMk5qVXlOVE13TURRMk9qRXpPRGM1T0RJeU1ERT0ZD
      after: WTI5dGJXVnVkRjlqZAFhKemIzSTZAOamMxTkRnek5qWTVNVFU0TURFeE9qRXpPRGd3TkRZAMU9ETT0ZD
